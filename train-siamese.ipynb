{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from datetime import datetime\n",
    "from math import ceil, floor\n",
    "from skimage.util import montage\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import Compose\n",
    "from typing import *\n",
    "import copy \n",
    "import cv2\n",
    "import glob\n",
    "import inspect\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "import random \n",
    "import scipy\n",
    "import sklearn\n",
    "import socket\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data_prep, dataset, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep.get_df_from_folder('/home/anuj/code/data/lfw_train')\n",
    "df_train, df_val = data_prep.split_train_val(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df_train.groupby('label').count() > 1), np.sum(df_val.groupby('label').count() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataloader_train = dataset.get_dataloader(df_train, batch_size=2*24)\n",
    "dataset_val, dataloader_val = dataset.get_dataloader(df_val, batch_size=2*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, batch in enumerate(dataloader_val):\n",
    "    if ix >= 2:\n",
    "        break\n",
    "    visualize.visualize(batch, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Optimizer, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import segnet\n",
    "from src.loss import ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segnet.SiameseNetworkLarge(256)\n",
    "model = torch.nn.DataParallel(model, device_ids=[2, 3]).cuda(device_id)\n",
    "\n",
    "# loss_func = torch.nn.NLLLoss(weight=None).cuda(device_id)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = ContrastiveLoss().cuda(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup loggging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_str = 'face-siamese-contrastive-2.04'\n",
    "weights_folder = f\"/home/anuj/weights/{model_str}\"\n",
    "writer = SummaryWriter(weights_folder) # writing log to tensorboard\n",
    "print('logging to: {}'.format(weights_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_loop(iter_start=0, max_epochs=100, val_every=50, save_every=500):\n",
    "    iter_cntr = iter_start\n",
    "    model.train(True)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            for batch in dataloader_train:\n",
    "                iter_cntr += 1\n",
    "\n",
    "                error_train = train.train_iter(\n",
    "                    batch=batch,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_func=loss_func,\n",
    "                    device=device_id\n",
    "                )\n",
    "\n",
    "                writer.add_scalar('train.loss', error_train, iter_cntr)\n",
    "\n",
    "                if iter_cntr%val_every==0:\n",
    "                    error_val, cm = train.evaluate(\n",
    "                        dataloader_val, model=model, loss=loss_func, device=device_id, n_iters=2\n",
    "                    )\n",
    "                    writer.add_scalar('val.loss', error_val, iter_cntr)\n",
    "#                     print(cm)\n",
    "\n",
    "                if iter_cntr%save_every==0:\n",
    "                    torch.save(model.state_dict(), \"%s/feat-%d.pt\"%(weights_folder,iter_cntr))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(model.state_dict(), \"%s/feat-%d.pt\"%(weights_folder,iter_cntr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/home/anuj/weights/face-siamese-contrastive-2.04/feat-5000.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training_loop(iter_start=5200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
