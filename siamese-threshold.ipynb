{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from datetime import datetime\n",
    "from math import ceil, floor\n",
    "from skimage.util import montage\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import Compose\n",
    "from typing import *\n",
    "import copy \n",
    "import cv2\n",
    "import glob\n",
    "import inspect\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "import random \n",
    "import scipy\n",
    "import sklearn\n",
    "import socket\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data_prep, dataset, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep.get_df_from_folder('/home/anuj/code/data/lfw_train')\n",
    "df_train, df_val = data_prep.split_train_val(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df_train.groupby('label').count() > 1), np.sum(df_val.groupby('label').count() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataloader_train = dataset.get_dataloader(df_train, image_side=160, batch_size=5*24)\n",
    "dataset_val, dataloader_val = dataset.get_dataloader(df_val, image_side=160, batch_size=5*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Optimizer, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import models\n",
    "from src.loss import ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.SiameseNet(160)\n",
    "model = torch.nn.DataParallel(model, device_ids=[1]).cuda(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.load_state_dict(torch.load('weights/face-siamese-crop.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_dist_vs_label(dataloader, n_iters=50):\n",
    "    all_labels, all_dists = [], []\n",
    "\n",
    "    for ix, batch in enumerate(dataloader):\n",
    "        if ix >= n_iters:\n",
    "            break\n",
    "        images1, images2, labels = dataset.flatten(batch) \n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats1, feats2 = model(images1, images2)\n",
    "            dist = torch.nn.functional.pairwise_distance(feats1, feats2)\n",
    "\n",
    "        all_labels.extend(labels.data.cpu().numpy())\n",
    "        all_dists.extend(dist.data.cpu().numpy())\n",
    "\n",
    "    all_dists = np.array(all_dists)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "#     df_dist_label = pd.DataFrame([all_dists, all_labels], index=['dist', 'label']).T\n",
    "    return all_dists, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_dists_train, all_labels_train = get_df_dist_vs_label(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_dists_val, all_labels_val = get_df_dist_vs_label(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs = [0.1, 0.2, 0.3, 0.5, 0.8, 1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in threshs:\n",
    "    preds = np.array(all_dists_train < thresh, dtype=np.int)\n",
    "    f1s = precision_recall_fscore_support(all_labels_train, preds)[2]\n",
    "    print(thresh, f1s, f1s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in threshs:\n",
    "    preds = np.array(all_dists_val < thresh, dtype=np.int)\n",
    "    f1s = precision_recall_fscore_support(all_labels_val, preds)[2]\n",
    "    print(thresh, f1s, f1s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data_prep.get_df_from_folder('/home/anuj/code/data/lfw_heldout/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, dataloader_test = dataset.get_dataloader(df_test, image_side=160, batch_size=5*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_dists_test, all_labels_test = get_df_dist_vs_label(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(all_dists_test < THRESH, dtype=np.int)\n",
    "print(THRESH, precision_recall_fscore_support(all_labels_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import predict\n",
    "\n",
    "\n",
    "def show_images(ax, image_path1, image_path2, label):\n",
    "    im1 = cv2.imread(image_path1)\n",
    "    im2 = cv2.imread(image_path2)\n",
    "    im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "    im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = np.hstack([im1, im2])\n",
    "    ax.imshow(image.astype(np.uint8))\n",
    "    ax.set_title(label)\n",
    "\n",
    "def visualize_preds(dataset, n=10, start=0, threshold=1.8):\n",
    "    plt.figure(figsize=(20, 50))\n",
    "    for ix in range(n):\n",
    "        idx1, idx2 = dataset[start+ix]['pairs'][ix%2]\n",
    "\n",
    "        i1 = str(dataset.df.loc[idx1]['path'])\n",
    "        i2 = str(dataset.df.loc[idx2]['path'])\n",
    "        # !python predict.py -img1 {i1} -img2 {i2}\n",
    "        dist, issame = predict.predict(i1, i2, model, transforms, 'cpu', threshold)\n",
    "        label = 'Dis-similarity: {:.2f}, Same person?: {}'.format(dist, bool(issame))\n",
    "\n",
    "        ax = plt.subplot(n, 2, ix+1)\n",
    "        show_images(ax, i1, i2, label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predict.get_model('cpu', 'weights/face-siamese-crop.pt')\n",
    "transforms = preprocess.get_transforms_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(dataset_train, n=10, start=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(dataset_val, n=10, start=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(dataset_test, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models import segnet\n",
    "\n",
    "def fix_weights(path, out, device):\n",
    "    state_dict = torch.load(path, map_location={'cuda:2': device})\n",
    "\n",
    "    m = torch.nn.DataParallel(segnet.SiameseNetworkLarge(160))\n",
    "    m.load_state_dict(state_dict)\n",
    "    torch.save(m.module.state_dict(), out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
